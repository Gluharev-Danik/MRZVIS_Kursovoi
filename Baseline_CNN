import os
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from tqdm import tqdm
from sklearn.metrics import accuracy_score, f1_score
import mlflow
import mlflow.pytorch

# –ü—É—Ç—å –∫ –¥–∞–Ω–Ω—ã–º (–æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ –ø—É—Ç–∏)
data_dir = '.'  # –¢–µ–∫—É—â–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –ø—Ä–æ–µ–∫—Ç–∞
train_dir = os.path.join(data_dir, 'train')
val_dir = os.path.join(data_dir, 'val')
test_dir = os.path.join(data_dir, 'test')

# –ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã
IMG_SIZE = 224
BATCH_SIZE = 32
EPOCHS = 10
LR = 0.001
NUM_WORKERS = 2 if os.cpu_count() > 2 else 0

# –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è: —Ç–æ–ª—å–∫–æ rescale
transform = transforms.Compose([
    transforms.Resize((IMG_SIZE, IMG_SIZE)),
    transforms.ToTensor(),
])

# –î–∞—Ç–∞—Å–µ—Ç—ã
train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)
val_dataset = datasets.ImageFolder(root=val_dir, transform=transform)
test_dataset = datasets.ImageFolder(root=test_dir, transform=transform)

# –î–∞—Ç–∞–ª–æ–∞–¥–µ—Ä—ã
train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)
val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)
test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)


# –ú–æ–¥–µ–ª—å: –ü—Ä–æ—Å—Ç–∞—è CNN
class SimpleCNN(nn.Module):
    def __init__(self):
        super(SimpleCNN, self).__init__()
        self.features = nn.Sequential(
            nn.Conv2d(3, 32, kernel_size=3),
            nn.MaxPool2d(2, 2),
            nn.Conv2d(32, 64, kernel_size=3),
            nn.MaxPool2d(2, 2),
            nn.Conv2d(64, 128, kernel_size=3),
            nn.MaxPool2d(2, 2),
        )
        self.classifier = nn.Sequential(
            nn.Flatten(),
            nn.Linear(128 * 26 * 26, 512),
            nn.ReLU(),
            nn.Linear(512, 1),
        )

    def forward(self, x):
        x = self.features(x)
        return self.classifier(x)


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –º–µ—Ç—Ä–∏–∫
def evaluate(loader, model, device, criterion):
    model.eval()
    all_preds = []
    all_labels = []
    total_loss = 0

    with torch.no_grad():
        for images, labels in loader:
            images, labels = images.to(device), labels.to(device).float()
            outputs = model(images).flatten()
            loss = criterion(outputs, labels)
            total_loss += loss.item()

            preds = (torch.sigmoid(outputs) > 0.5).cpu().numpy()
            all_preds.extend(preds)
            all_labels.extend(labels.cpu().numpy())

    acc = accuracy_score(all_labels, all_preds)
    f1 = f1_score(all_labels, all_preds, average='binary')
    avg_loss = total_loss / len(loader)

    return acc, f1, avg_loss


# –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è
def main():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
    model = SimpleCNN().to(device)

    # –§—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä
    criterion = nn.BCEWithLogitsLoss()
    optimizer = optim.Adam(model.parameters(), lr=LR)

    with mlflow.start_run():

        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        mlflow.log_params({
            "batch_size": BATCH_SIZE,
            "learning_rate": LR,
            "epochs": EPOCHS,
            "num_workers": NUM_WORKERS,
            "image_size": IMG_SIZE
        })

        # –û–±—É—á–µ–Ω–∏–µ
        for epoch in range(EPOCHS):
            model.train()
            running_loss = 0.0
            all_train_preds = []
            all_train_labels = []

            progress_bar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{EPOCHS}")
            for images, labels in progress_bar:
                images, labels = images.to(device), labels.to(device).float()

                optimizer.zero_grad()
                outputs = model(images).flatten()
                loss = criterion(outputs, labels)
                loss.backward()
                optimizer.step()

                running_loss += loss.item()
                preds = (torch.sigmoid(outputs) > 0.5).cpu().numpy()
                all_train_preds.extend(preds)
                all_train_labels.extend(labels.cpu().numpy())

                progress_bar.set_postfix(loss=loss.item())

            train_acc = accuracy_score(all_train_labels, all_train_preds)
            train_f1 = f1_score(all_train_labels, all_train_preds, average='binary')
            train_loss = running_loss / len(train_loader)

            # –õ–æ–≥–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏ train
            mlflow.log_metrics({
                "train_loss": train_loss,
                "train_acc": train_acc,
                "train_f1": train_f1
            }, step=epoch)

            # –í–∞–ª–∏–¥–∞—Ü–∏—è
            val_acc, val_f1, val_loss = evaluate(val_loader, model, device, criterion)

            # –õ–æ–≥–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏ val
            mlflow.log_metrics({
                "val_loss": val_loss,
                "val_acc": val_acc,
                "val_f1": val_f1
            }, step=epoch)

            print(f"Epoch {epoch+1} | "
                  f"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Train F1: {train_f1:.4f} | "
                  f"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, Val F1: {val_f1:.4f}")

        # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
        test_acc, test_f1, test_loss = evaluate(test_loader, model, device, criterion)

        # –õ–æ–≥–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏ test
        mlflow.log_metrics({
            "test_loss": test_loss,
            "test_acc": test_acc,
            "test_f1": test_f1
        })

        print(f"\nTest Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}, Test F1: {test_f1:.4f}")

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        mlflow.pytorch.log_model(model, "model")


# üî• –ó–ê–ü–£–°–ö –ß–ï–†–ï–ó MAIN
if __name__ == '__main__':
    main()
